schema: catalog.nkp.nutanix.com/v1/application-metadata
displayName: Spark Operator
allowMultipleInstances: false
category:
  - dm-nkp-gitops-app-catalog
  - ai
  - infrastructure
  - data
description: |
  The Kubernetes operator for Apache Spark: run Spark applications as native
  Kubernetes resources. Manages driver and executor pods, submission, and
  lifecycle. Part of the Kubeflow ecosystem for data and ML workloads.
dependencies: []
icon: ""
licensing:
  - Pro
  - Ultimate
overview: |
  **What it is** â€” The Spark on Kubernetes operator lets you run Apache Spark jobs and applications as Kubernetes-native workloads, with drivers and executors as pods.

  **Highlights**
  - Submit Spark applications via custom resources (SparkApplication); no need to manage pods manually
  - Supports batch and streaming; integrates with Hive, S3, and other data sources
  - Used by Kubeflow Pipelines and other ML/data workflows on Kubernetes
  - Community-driven; part of the Kubeflow manifests and ecosystem

  **Documentation:** [Spark on K8s](https://spark.apache.org/docs/latest/running-on-kubernetes.html) | **Project:** [Kubeflow Spark](https://github.com/kubeflow/manifests/tree/master/applications/spark/spark-operator)
scope:
  - workspace
  - project
supportLink: https://github.com/kubeflow/manifests/tree/master/applications/spark/spark-operator
type: custom
